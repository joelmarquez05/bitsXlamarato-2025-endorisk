{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 - Data Preprocessing\n",
                "\n",
                "**Purpose**: Clean data, encode, scale, split, and SAVE for next notebook.\n",
                "\n",
                "**Outputs**:\n",
                "- `data/processed/features_v1_train.csv`\n",
                "- `data/processed/features_v1_test.csv`\n",
                "- `models/scaler_v1.joblib`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys; sys.path.append('..')\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "from src.preprocessing import clean_missing_values, encode_categorical, scale_numerical\n",
                "from src.features import create_clinical_features\n",
                "\n",
                "# === SETTINGS (edit these) ===\n",
                "TARGET_COL = 'recurrence'\n",
                "TEST_SIZE = 0.2\n",
                "RANDOM_STATE = 42\n",
                "VERSION = 'v1'  # Increment when making changes\n",
                "\n",
                "print(\"✅ Setup complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Load your data\n",
                "# df = pd.read_csv('../data/raw/YOUR_DATA.csv')\n",
                "\n",
                "# Mock data\n",
                "print(\"⚠️ Using MOCK DATA\")\n",
                "np.random.seed(42)\n",
                "n = 500\n",
                "df = pd.DataFrame({\n",
                "    'patient_id': range(1, n+1),\n",
                "    'age': np.random.normal(62, 10, n).astype(int),\n",
                "    'grade': np.random.choice([1, 2, 3], n, p=[0.3, 0.5, 0.2]),\n",
                "    'histology': np.random.choice(['Endometrioid', 'Serous', 'Clear Cell'], n),\n",
                "    'lvsi': np.random.choice(['Yes', 'No'], n, p=[0.3, 0.7]),\n",
                "    'myometrial_invasion': np.random.uniform(0, 1, n).round(2),\n",
                "    'tumor_size': np.random.exponential(3, n).round(1),\n",
                "    'recurrence': np.random.choice([0, 1], n, p=[0.75, 0.25])\n",
                "})\n",
                "df.loc[np.random.choice(df.index, 20), 'tumor_size'] = np.nan  # Add missing\n",
                "print(f\"Raw data: {df.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean missing values\n",
                "df_clean = clean_missing_values(df)\n",
                "\n",
                "# Feature engineering\n",
                "df_features = create_clinical_features(df_clean)\n",
                "\n",
                "# Encode categorical\n",
                "cat_cols = df_features.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "df_encoded, encoders = encode_categorical(df_features, columns=cat_cols, method='onehot')\n",
                "\n",
                "print(f\"After preprocessing: {df_encoded.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/test split\n",
                "drop_cols = [c for c in ['patient_id', TARGET_COL] if c in df_encoded.columns]\n",
                "X = df_encoded.drop(columns=drop_cols)\n",
                "y = df_encoded[TARGET_COL]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
                ")\n",
                "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scale numerical (fit on train only!)\n",
                "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
                "X_train_scaled, scaler = scale_numerical(X_train, columns=num_cols)\n",
                "X_test_scaled = X_test.copy()\n",
                "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SAVE for next notebook\n",
                "train_data = X_train_scaled.copy()\n",
                "train_data[TARGET_COL] = y_train.values\n",
                "test_data = X_test_scaled.copy()\n",
                "test_data[TARGET_COL] = y_test.values\n",
                "\n",
                "train_data.to_csv(f'../data/processed/features_{VERSION}_train.csv', index=False)\n",
                "test_data.to_csv(f'../data/processed/features_{VERSION}_test.csv', index=False)\n",
                "joblib.dump(scaler, f'../models/scaler_{VERSION}.joblib')\n",
                "joblib.dump(list(X_train.columns), f'../models/feature_names_{VERSION}.joblib')\n",
                "\n",
                "print(f\"\\n✅ SAVED:\")\n",
                "print(f\"   data/processed/features_{VERSION}_train.csv\")\n",
                "print(f\"   data/processed/features_{VERSION}_test.csv\")\n",
                "print(f\"   models/scaler_{VERSION}.joblib\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Step\n",
                "→ Go to `03_model_training.ipynb`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
